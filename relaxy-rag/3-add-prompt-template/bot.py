import streamlit as st
import requests
from datetime import datetime
import time
import os
from langchain.prompts import ChatPromptTemplate
from langchain.schema import AIMessage, HumanMessage, SystemMessage
import unicodedata



#System Prompts for Each Mode : Scribe, emotional, teaching and urgency
SCRIBE_PROMPT = """ржЖржкржирж┐ ржПржХржЬржи рж╕рж╣рж╛ржирзБржнрзВрждрж┐рж╢рзАрж▓ ржмрж╛ржВрж▓рж╛ ржерзЗрж░рж╛ржкрж┐рж╕рзНржЯред
ржЖржкржирж╛рж░ ржорзВрж▓ ржХрж╛ржЬ рж╣рж▓рзЛ ржЗржЙржЬрж╛рж░рзЗрж░ ржХржерж╛ржЧрзБрж▓рзЛ ржоржирзЛржпрзЛржЧ ржжрж┐рзЯрзЗ рж╢рзЛржирж╛ ржПржмржВ рж╕ржВржХрзНрж╖рзЗржкрзЗ ржкрзНрж░рждрж┐ржлрж▓ржи ржХрж░рж╛ред ржХрзЛржи ржкрж░рж╛ржорж░рзНрж╢, рж╕ржорж╛ржзрж╛ржи ржмрж╛ ржкрзНрж░рж╢ржВрж╕рж╛ ржирж╛ ржжрж┐рзЯрзЗ рж╢рзБржзрзБржорж╛рждрзНрж░ рж╕рж╣рж╛ржирзБржнрзВрждрж┐рж░ рж╕рж╛ржерзЗ ржЙрждрзНрждрж░ ржжрж┐ржиред"""

EMOTIONAL_SUPPORT = """ржЖржкржирж┐ ржПржЦржи ржЗржорзЛрж╢ржирж╛рж▓ рж╕рж╛ржкрзЛрж░рзНржЯ ржорзЛржбрзЗ ржЖржЫрзЗржиред ржЗржЙржЬрж╛рж░ ржпржжрж┐ ржХрж╖рзНржЯ, рж╣рждрж╛рж╢рж╛ ржмрж╛ ржПржХрж╛ржХрзАрждрзНржм ржкрзНрж░ржХрж╛рж╢ ржХрж░рзЗ, рждрж╛рж╣рж▓рзЗ рж╕рж╣рж╛ржирзБржнрзВрждрж┐рж╢рзАрж▓ ржПржмржВ рж╕рж╛ржирзНрждрзНржмржирж╛ржжрж╛ржпрж╝ржХ ржнрж╛рж╖рж╛ржпрж╝ ржХржерж╛ ржмрж▓рзБржиред"""

TEACHING_MODE = """ржЖржкржирж┐ ржПржЦржи ржПржХржЯрж┐ ржмрж╛ржВрж▓рж╛ ржХрзНрж▓рж┐ржирж┐ржХрж╛рж▓ рж╕рж╛ржЗржХрзЛрж▓ржЬрж┐рж╕рзНржЯред ржЗржЙржЬрж╛рж░ ржпржжрж┐ ржХрзЛржирзЛ ржЯрж┐ржкрж╕, ржХрзМрж╢рж▓ ржмрж╛ ржмрзНржпрж╛ржЦрзНржпрж╛рж░ ржЕржирзБрж░рзЛржз ржХрж░рзЗ, рждрж╛рж╣рж▓рзЗ рж╕рзНржкрж╖рзНржЯржнрж╛ржмрзЗ ржПржмржВ рж╕рж╣ржЬ ржмрж╛ржВрж▓рж╛ржпрж╝ ржкржжржХрзНрж╖рзЗржкржнрж┐рждрзНрждрж┐ржХ рждржерзНржп ржжрж┐ржиред"""

URGENCY_MODE = """ржЖржкржирж┐ ржПржЦржи ржЬрж░рзБрж░рж┐ рж╕рж╣рж╛ржпрж╝рждрж╛ ржорзЛржбрзЗ ржЖржЫрзЗржиред ржЗржЙржЬрж╛рж░ ржпржжрж┐ ржЖрждрзНржорж╣рждрзНржпрж╛ ржмрж╛ ржЪрж░ржо рж╕ржВржХржЯрзЗрж░ ржЗржЩрзНржЧрж┐ржд ржжрзЗржпрж╝, рждрж╛рж╣рж▓рзЗ рж╕рж╣рж╛ржирзБржнрзВрждрж┐рж░ рж╕рж╛ржерзЗ ржЬрж░рзБрж░рж┐ рж╕рж╣рж╛ржпрж╝рждрж╛рж░ ржЬржирзНржп https://session.relaxy.com.bd/ ржПржжрзЗрж░ ржерзЗржХрзЗ рж╕рж╛ржкрзЛрж░рзНржЯ ржирж┐рждрзЗ ржмрж▓рзБржи ржПржмржВ рждрж╛ржжрзЗрж░ ржПржХрж╛ ржирж╛ ржерж╛ржХрж╛рж░ ржкрж░рж╛ржорж░рзНрж╢ ржжрж┐ржиред"""

def normalize_bangla_text(text):
    """Normalize Bangla text by removing diacritics and standardizing characters"""
    # Convert to Unicode normalized form
    text = unicodedata.normalize('NFKC', text)
    return text

def detect_mode(prompt):
    # Normalize the input text
    prompt = normalize_bangla_text(prompt.lower())
    
    # Define keywords for each mode with normalized Bangla text
    urgency_keywords = ["ржорж░рждрзЗ", "ржЖрждрзНржорж╣рждрзНржпрж╛", "рж╢рзЗрж╖ ржХрж░рзЗ ржжрж┐рждрзЗ", "ржорж░рзЗ ржпрж╛ржм", "ржЬрзАржмржи рж╢рзЗрж╖"]
    emotional_keywords = ["ржХрж╖рзНржЯ", "ржоржи ржЦрж╛рж░рж╛ржк", "ржПржХрж╛ржХрзА", "ржПржХрж╛ ржПржХрж╛ рж▓рж╛ржЧрж╛", "рж╕рзНржЯрзНрж░рзЗрж╕", "ржжрзБржГржЦ", "ржмрж┐рж╖ржгрзНржг"]
    teaching_keywords = ["ржХрж┐ ржХрж░ржмрзЛ", "ржХрзАржнрж╛ржмрзЗ", "help", "ржЙржкрж╛ржпрж╝", "рж╕ржорж╛ржзрж╛ржи", "ржкрж░рж╛ржорж░рзНрж╢"]
    
    if any(term in prompt for term in urgency_keywords):
        return URGENCY_MODE
    elif any(term in prompt for term in emotional_keywords):
        return EMOTIONAL_SUPPORT
    elif any(term in prompt for term in teaching_keywords):
        return TEACHING_MODE
    else:
        return SCRIBE_PROMPT


# Page setup with proper encoding
st.set_page_config(page_title="ржмрж╛ржВрж▓рж╛ ржерзЗрж░рж╛ржкрж┐ ржЪрзНржпрж╛ржЯржмржЯ", page_icon="ЁЯза", layout="wide")

# Sidebar setup
with st.sidebar:
    st.title("тЪЩя╕П Settings")

    # Show current working directory
    cwd = os.getcwd()
    
    st.markdown("ЁЯУБ **Current Working Directory:**")
    st.code(cwd)

    file_path = os.path.join(cwd, "..", "therapy_knowledge.txt")
    st.markdown("ЁЯУД **Trying to load file from:**")
    st.code(file_path)

    # Load the file with proper encoding
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            docs = f.readlines()
            # Normalize Bangla text in documents
            docs = [normalize_bangla_text(doc) for doc in docs]
            st.session_state.documents = docs
            st.success("тЬЕ File loaded successfully!")
            st.markdown("ЁЯУД Preview of file:")
            st.code("".join(docs[:5]), language="text")
    except Exception as e:
        st.error(f"тЭМ File loading failed:\n{e}")

    # Server status check
    try:
        requests.get("http://127.0.0.1:1234/v1/models", timeout=5)
        st.success("тЬЕ рж▓рзЛржХрж╛рж▓ ржоржбрзЗрж▓ ржХрж╛ржирзЗржХрзНржЯрзЗржб")
    except:
        st.error("тЭМ рж╕рж╛рж░рзНржнрж╛рж░ ржЪрж╛рж▓рзБ ржирж╛ржЗ")

    # Clear history button
    if st.button("ЁЯЧСя╕П Clear chat history"):
        st.session_state.messages = []
        st.rerun()

# Session state initialization
if "messages" not in st.session_state:
    st.session_state.messages = []

if "documents" not in st.session_state:
    st.session_state.documents = []

# Context retrieval function with normalized text
def retrieve_context(user_prompt):
    normalized_prompt = normalize_bangla_text(user_prompt.lower())
    keywords = normalized_prompt.split()
    relevant = [doc for doc in st.session_state.documents if any(word in doc.lower() for word in keywords)]
    return "\n".join(relevant[:3])

# Query the local LLM with proper text handling
def query_llm(user_prompt):
    try:
        # Normalize the input prompt
        normalized_prompt = normalize_bangla_text(user_prompt)
        context = retrieve_context(normalized_prompt)
        mode_prompt = detect_mode(normalized_prompt)
        
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", "ржЖржкржирж┐ ржПржХржЬржи рж╕рж╣рж╛ржирзБржнрзВрждрж┐рж╢рзАрж▓ ржмрж╛ржВрж▓рж╛ ржерзЗрж░рж╛ржкрж┐рж╕рзНржЯред ржирж┐ржЪрзЗ ржХрж┐ржЫрзБ ржХржиржЯрзЗржХрзНрж╕ржЯ ржжрзЗржпрж╝рж╛ рж╣рж▓рзЛ:\n{context}"),
            ("user", "{question}")
        ])
        
        final_prompt = f"""{mode_prompt}\n\nрж╕рж╛ржзрж╛рж░ржг ржЬрзНржЮрж╛ржи:\n{context}\n\nржкрзНрж░рж╢рзНржи: {normalized_prompt}"""

        response = requests.post(
            "http://127.0.0.1:1234/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json={
                "model": "qwen1.5-1.8b-chat",
                "messages": [{"role": "user", "content": final_prompt}],
                "temperature": 0.7,
                "max_tokens": 500
            },
            timeout=20
        )

        if response.status_code == 200:
            data = response.json()
            return data["choices"][0]["message"]["content"]
        else:
            return f"тЭМ API рждрзНрж░рзБржЯрж┐: {response.status_code} - {response.text}"

    except requests.Timeout:
        return "тЭМ рж╕ржоржпрж╝ рж╢рзЗрж╖ ржнрж╛ржЗржпрж╝рж╛ред"
    except requests.ConnectionError:
        return "тЭМ рж╕рж╛рж░рзНржнрж╛рж░рзЗ рж╕ржВржпрзЛржЧ ржкрж╛ржЗржирж╛ред LM Studio ржЪрж╛рж▓рзБ ржЖржЫрзЗ ржХрж┐ржирж╛ ржжрзНржпрж╛ржЦ?ред"
    except Exception as e:
        return f"тЭМ рждрзНрж░рзБржЯрж┐:\n{e}"

# Main content
st.title("ЁЯза ржмрж╛ржВрж▓рж╛ ржерзЗрж░рж╛ржкрж┐ ржЪрзНржпрж╛ржЯржмржЯ ЁЯдЦЁЯТм")

# Show chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        st.caption(message["timestamp"])

# Chat input from user with proper encoding
if prompt := st.chat_input("тЬНя╕П ржХрж┐ ржнрж╛ржмрзЗржи? ржЖржорж╛рж░ рж╕рж╛ржерзЗ ржХржерж╛ ржмрж▓рзЗржи..."):
    # Normalize the input prompt
    normalized_prompt = normalize_bangla_text(prompt)
    
    # Save user message
    st.session_state.messages.append({
        "role": "user",
        "content": normalized_prompt,
        "timestamp": datetime.now().strftime("%H:%M")
    })

    # Display user message
    with st.chat_message("user"):
        st.markdown(normalized_prompt)
        st.caption(datetime.now().strftime("%H:%M"))

    # Get assistant response
    with st.chat_message("assistant"):
        with st.spinner("тП│ ржнрж╛ржмржЫрж┐..."):
            start_time = time.time()
            response = query_llm(normalized_prompt)
            end_time = time.time()

            st.markdown(response)
            st.caption(f"{datetime.now().strftime('%H:%M')} тАв {end_time - start_time:.1f} рж╕рзЗржХрзЗржирзНржб")

            st.session_state.messages.append({
                "role": "assistant",
                "content": response,
                "timestamp": datetime.now().strftime("%H:%M")
            })

# Footer
st.markdown("---")
st.markdown("Made with тЭдя╕П using Streamlit + qwen1.5-1.8b-chat + LangChain")
